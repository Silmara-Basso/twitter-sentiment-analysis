{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944cbf5c",
   "metadata": {},
   "source": [
    "# <font color='blue'>Sentiment Analysis</font>\n",
    "# <font color='blue'> Analise de sentimento de um tweet  </font>\n",
    "\n",
    "### <font color='blue'>An√°lise de Sentimentos em Posts do Twitter</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac806f",
   "metadata": {},
   "source": [
    "## Instalando e Carregando os Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8303c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vers√£o da Linguagem Python Usada Neste Jupyter Notebook: 3.12.3\n"
     ]
    }
   ],
   "source": [
    "# Vers√£o da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Vers√£o da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5122c8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (25.3)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "!python3 -m venv svenv\n",
    "!source svenv/bin/activate\n",
    "!pyenv local 3.12.3\n",
    "!python3 -m pip install --upgrade pip\n",
    "\n",
    "!python3 -m pip install -q -U watermark\n",
    "!python3 -m pip install --upgrade certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e708efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re                                \n",
    "import nltk\n",
    "import string \n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt                           \n",
    "from nltk.corpus import stopwords          \n",
    "from nltk.stem import PorterStemmer        \n",
    "from nltk.tokenize import TweetTokenizer \n",
    "import os, ssl, certifi, urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b778adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sentiment\n",
      "\n",
      "nltk      : 3.9.1\n",
      "pandas    : 2.2.3\n",
      "certifi   : 2025.10.5\n",
      "re        : 2.2.1\n",
      "numpy     : 1.26.2\n",
      "matplotlib: 3.10.3\n",
      "platform  : 1.0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vers√µes dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Sentiment\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c534f",
   "metadata": {},
   "source": [
    "## Extra√ß√£o e Carga dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e78ed79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31b3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_ctx = ssl.create_default_context(cafile=certifi.where())\n",
    "opener = urllib.request.build_opener(urllib.request.HTTPSHandler(context=ssl_ctx))\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "158b4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"nltk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e54b355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/silmarabasso/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download as amostras de dados\n",
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2befdc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/silmarabasso/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download as stopwords ex. e, dos, de...\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79cced64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/silmarabasso/repos/twitter-sentiment-analysis'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica a pasta corrente\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12656e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o Corpus (dados)\n",
    "from nltk.corpus import twitter_samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0e43e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.util.LazyCorpusLoader"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(twitter_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f55dbe2",
   "metadata": {},
   "source": [
    "## Prepara√ß√£o dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101ff38",
   "metadata": {},
   "source": [
    "O objeto `twitter_samples` cont√©m subconjuntos de 5 mil tweets positivos, 5 mil tweets negativos e o conjunto completo de 10.000 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbd225fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamos os tweets positivos\n",
    "tweets_positivos = twitter_samples.strings('positive_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9d403cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_positivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9621e64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!',\n",
       " '@97sides CONGRATS :)',\n",
       " 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days',\n",
       " '@BhaktisBanter @PallaviRuhail This one is irresistible :)\\n#FlipkartFashionFriday http://t.co/EbZ0L2VENM',\n",
       " \"We don't like to keep our lovely customers waiting for long! We hope you enjoy! Happy Friday! - LWWF :) https://t.co/smyYriipxI\",\n",
       " '@Impatientraider On second thought, there‚Äôs just not enough time for a DD :) But new shorts entering system. Sheep must be buying.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizamos alguns tweets positivos\n",
    "tweets_positivos[2:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fa49926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamos os tweets negativos\n",
    "tweets_negativos = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d25baaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_negativos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20236f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@Hegelbon That heart sliding into the waste basket. :(',\n",
       " '‚Äú@ketchBurning: I hate Japanese call him \"bani\" :( :(‚Äù\\n\\nMe too',\n",
       " 'Dang starting next week I have \"work\" :(',\n",
       " \"oh god, my babies' faces :( https://t.co/9fcwGvaki0\",\n",
       " '@RileyMcDonough make me smile :((',\n",
       " '@f0ggstar @stuartthull work neighbour on motors. Asked why and he said hates the updates on search :( http://t.co/XvmTUikWln']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizamos alguns tweets negativos\n",
    "tweets_negativos[2:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47d0d01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweets_negativos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956fd895",
   "metadata": {},
   "source": [
    "## Divis√£o em Treino e Teste\n",
    "\n",
    "Dividir os dados com uma propor√ß√£o 80/20 (treino/teste) garantindo a mesma propor√ß√£o de tweets positivos e negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7580340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dos dados de tweets positivos - 1000 tweets para dados de teste e 4000 tweets para dados de treino\n",
    "tweets_positivos_teste = tweets_positivos[4000:]\n",
    "tweets_positivos_treino = tweets_positivos[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8fd9d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dos dados de tweets negativos - 1000 tweets para dados de teste e 4000 tweets para dados de treino\n",
    "tweets_negativos_teste = tweets_negativos[4000:]\n",
    "tweets_negativos_treino = tweets_negativos[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fbd726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena os dados de treino\n",
    "dados_treino_x = tweets_positivos_treino + tweets_negativos_treino "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "331b2826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dados_treino_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c228b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena os dados de teste\n",
    "dados_teste_x = tweets_positivos_teste + tweets_negativos_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f9b67f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dados_teste_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d109a",
   "metadata": {},
   "source": [
    "> Vetor (array) numpy de r√≥tulos positivos e negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf2e2b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinando labels positivos e negativos de treino\n",
    "y_treino = np.append(np.ones((len(tweets_positivos_treino), 1)), \n",
    "                     np.zeros((len(tweets_negativos_treino), 1)), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c36451a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8c0a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinando labels positivos e negativos de teste\n",
    "y_teste = np.append(np.ones((len(tweets_positivos_teste), 1)), \n",
    "                    np.zeros((len(tweets_negativos_teste), 1)), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6a75ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478767c",
   "metadata": {},
   "source": [
    "## Manipula√ß√£o de Texto e Pr√©-Processamento dos Dados\n",
    "\n",
    "Fun√ß√£o para processar o texto dos posts do Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bb558d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para limpeza e processamento do texto dos tweets\n",
    "def limpa_processa_tweet(tweet):\n",
    "   \n",
    "    # Stop words\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    \n",
    "    # Remove stock market tickers (s√≠mbolo $GE)\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    \n",
    "    # Remove texto de retweet (\"RT\")\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    \n",
    "    # Remove hyperlinks\n",
    "    tweet = re.sub(r'http?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    \n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    # Cria um tokenizador (separa frases em palavras)\n",
    "    tokenizer = TweetTokenizer(preserve_case = False, strip_handles = True, reduce_len = True)\n",
    "    \n",
    "    # Aplica o tokenizador\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    # Lista para os tweets limpos\n",
    "    tweets_clean = []\n",
    "    \n",
    "    # Cria o objeto Stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Loop\n",
    "    for word in tweet_tokens:\n",
    "        \n",
    "        # Removemos stop words e pontua√ß√£o\n",
    "        if (word not in stopwords_english and word not in string.punctuation):  \n",
    "            \n",
    "            # Stemming (extraindo os radicais das palavras)\n",
    "            stem_word = stemmer.stem(word)  \n",
    "            \n",
    "            # Tweets limpos\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127a283c",
   "metadata": {},
   "source": [
    "> Teste do processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d01ccef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este √© um exemplo de um tweet positivo original: \n",
      "\n",
      " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n"
     ]
    }
   ],
   "source": [
    "print('Este √© um exemplo de um tweet positivo original: \\n\\n', dados_treino_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "082ab8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Este √© um exemplo da vers√£o processada do tweet: \n",
      "\n",
      " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
     ]
    }
   ],
   "source": [
    "print('\\nEste √© um exemplo da vers√£o processada do tweet: \\n\\n', limpa_processa_tweet(dados_treino_x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd7ebf",
   "metadata": {},
   "source": [
    "> Fun√ß√£o para construir o dicion√°rio de frequ√™ncia das palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bc9a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para criar o dicion√°rio de frequ√™ncia\n",
    "def cria_freqs(tweets, ys):\n",
    "    \n",
    "    # tweets √© uma lista de tweets\n",
    "    # ys √© um array m x 1 com um label de sentimento para cada tweet (0 ou 1)\n",
    "   \n",
    "    # Sqeeeze (remove uma das dimens√µes)\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    # Dicion√°rio de frequ√™ncias\n",
    "    freqs = {}\n",
    "    \n",
    "    # Loop para cada tweet\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        \n",
    "        # Loop para cada palavra\n",
    "        for word in limpa_processa_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "        \n",
    "    return freqs        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "708f95fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n",
       " '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!',\n",
       " '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!',\n",
       " '@97sides CONGRATS :)',\n",
       " 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treino_x[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9befcef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treino[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0049403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a fun√ß√£o aos dados de treino\n",
    "freqs = cria_freqs(dados_treino_x, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a65cfca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08e456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('long', 1.0): 27,\n",
       " ('hope', 1.0): 113,\n",
       " ('enjoy', 1.0): 57,\n",
       " ('happi', 1.0): 161,\n",
       " ('friday', 1.0): 91}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#positivos\n",
    "dict(list(freqs.items())[50:55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7c39c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('oil', 0.0): 1,\n",
       " ('massag', 0.0): 5,\n",
       " ('everyday', 0.0): 5,\n",
       " ('healthier', 0.0): 1,\n",
       " ('easier', 0.0): 3}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#negativos\n",
    "dict(list(freqs.items())[6995:7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f004638b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('followfriday', 1.0): 23,\n",
       " ('top', 1.0): 30,\n",
       " ('engag', 1.0): 7,\n",
       " ('member', 1.0): 14,\n",
       " ('commun', 1.0): 27,\n",
       " ('week', 1.0): 72,\n",
       " (':)', 1.0): 2847,\n",
       " ('hey', 1.0): 60,\n",
       " ('jame', 1.0): 7,\n",
       " ('odd', 1.0): 2,\n",
       " (':/', 1.0): 5,\n",
       " ('pleas', 1.0): 80,\n",
       " ('call', 1.0): 27,\n",
       " ('contact', 1.0): 4,\n",
       " ('centr', 1.0): 1,\n",
       " ('02392441234', 1.0): 1,\n",
       " ('abl', 1.0): 6,\n",
       " ('assist', 1.0): 1,\n",
       " ('mani', 1.0): 28,\n",
       " ('thank', 1.0): 504,\n",
       " ('listen', 1.0): 14,\n",
       " ('last', 1.0): 39,\n",
       " ('night', 1.0): 55,\n",
       " ('bleed', 1.0): 2,\n",
       " ('amaz', 1.0): 41,\n",
       " ('track', 1.0): 5,\n",
       " ('scotland', 1.0): 2,\n",
       " ('congrat', 1.0): 15,\n",
       " ('yeaaah', 1.0): 1,\n",
       " ('yipppi', 1.0): 1,\n",
       " ('accnt', 1.0): 2,\n",
       " ('verifi', 1.0): 2,\n",
       " ('rqst', 1.0): 1,\n",
       " ('succeed', 1.0): 1,\n",
       " ('got', 1.0): 57,\n",
       " ('blue', 1.0): 8,\n",
       " ('tick', 1.0): 1,\n",
       " ('mark', 1.0): 1,\n",
       " ('fb', 1.0): 4,\n",
       " ('profil', 1.0): 2,\n",
       " ('15', 1.0): 4,\n",
       " ('day', 1.0): 187,\n",
       " ('one', 1.0): 90,\n",
       " ('irresist', 1.0): 2,\n",
       " ('flipkartfashionfriday', 1.0): 16,\n",
       " ('like', 1.0): 187,\n",
       " ('keep', 1.0): 55,\n",
       " ('love', 1.0): 336,\n",
       " ('custom', 1.0): 4,\n",
       " ('wait', 1.0): 55,\n",
       " ('long', 1.0): 27,\n",
       " ('hope', 1.0): 113,\n",
       " ('enjoy', 1.0): 57,\n",
       " ('happi', 1.0): 161,\n",
       " ('friday', 1.0): 91,\n",
       " ('lwwf', 1.0): 1,\n",
       " ('second', 1.0): 8,\n",
       " ('thought', 1.0): 21,\n",
       " ('‚Äô', 1.0): 17,\n",
       " ('enough', 1.0): 16,\n",
       " ('time', 1.0): 100,\n",
       " ('dd', 1.0): 1,\n",
       " ('new', 1.0): 111,\n",
       " ('short', 1.0): 6,\n",
       " ('enter', 1.0): 9,\n",
       " ('system', 1.0): 2,\n",
       " ('sheep', 1.0): 1,\n",
       " ('must', 1.0): 14,\n",
       " ('buy', 1.0): 9,\n",
       " ('jgh', 1.0): 4,\n",
       " ('go', 1.0): 120,\n",
       " ('bayan', 1.0): 1,\n",
       " (':d', 1.0): 498,\n",
       " ('bye', 1.0): 5,\n",
       " ('act', 1.0): 6,\n",
       " ('mischiev', 1.0): 1,\n",
       " ('etl', 1.0): 1,\n",
       " ('layer', 1.0): 1,\n",
       " ('in-hous', 1.0): 1,\n",
       " ('wareh', 1.0): 1,\n",
       " ('app', 1.0): 12,\n",
       " ('katamari', 1.0): 1,\n",
       " ('well', 1.0): 66,\n",
       " ('‚Ä¶', 1.0): 31,\n",
       " ('name', 1.0): 12,\n",
       " ('impli', 1.0): 1,\n",
       " (':p', 1.0): 104,\n",
       " ('influenc', 1.0): 16,\n",
       " ('big', 1.0): 27,\n",
       " ('...', 1.0): 227,\n",
       " ('juici', 1.0): 3,\n",
       " ('selfi', 1.0): 11,\n",
       " ('follow', 1.0): 319,\n",
       " ('perfect', 1.0): 17,\n",
       " ('alreadi', 1.0): 19,\n",
       " ('know', 1.0): 120,\n",
       " (\"what'\", 1.0): 14,\n",
       " ('great', 1.0): 134,\n",
       " ('opportun', 1.0): 17,\n",
       " ('junior', 1.0): 2,\n",
       " ('triathlet', 1.0): 1,\n",
       " ('age', 1.0): 2,\n",
       " ('12', 1.0): 5,\n",
       " ('13', 1.0): 5,\n",
       " ('gatorad', 1.0): 1,\n",
       " ('seri', 1.0): 4,\n",
       " ('get', 1.0): 164,\n",
       " ('entri', 1.0): 3,\n",
       " ('lay', 1.0): 3,\n",
       " ('greet', 1.0): 4,\n",
       " ('card', 1.0): 6,\n",
       " ('rang', 1.0): 2,\n",
       " ('print', 1.0): 3,\n",
       " ('today', 1.0): 86,\n",
       " ('job', 1.0): 34,\n",
       " (':-)', 1.0): 543,\n",
       " (\"friend'\", 1.0): 3,\n",
       " ('lunch', 1.0): 3,\n",
       " ('yummm', 1.0): 1,\n",
       " ('nostalgia', 1.0): 1,\n",
       " ('tb', 1.0): 1,\n",
       " ('ku', 1.0): 1,\n",
       " ('id', 1.0): 8,\n",
       " ('conflict', 1.0): 1,\n",
       " ('help', 1.0): 37,\n",
       " (\"here'\", 1.0): 20,\n",
       " ('screenshot', 1.0): 2,\n",
       " ('work', 1.0): 88,\n",
       " ('hi', 1.0): 154,\n",
       " ('liv', 1.0): 2,\n",
       " ('hello', 1.0): 49,\n",
       " ('need', 1.0): 62,\n",
       " ('someth', 1.0): 25,\n",
       " ('u', 1.0): 136,\n",
       " ('fm', 1.0): 2,\n",
       " ('twitter', 1.0): 25,\n",
       " ('‚Äî', 1.0): 22,\n",
       " ('sure', 1.0): 37,\n",
       " ('thing', 1.0): 48,\n",
       " ('dm', 1.0): 34,\n",
       " ('x', 1.0): 50,\n",
       " ('heard', 1.0): 9,\n",
       " ('four', 1.0): 5,\n",
       " ('season', 1.0): 5,\n",
       " ('pretti', 1.0): 17,\n",
       " ('dope', 1.0): 2,\n",
       " ('penthous', 1.0): 1,\n",
       " ('obv', 1.0): 1,\n",
       " ('gobigorgohom', 1.0): 1,\n",
       " ('fun', 1.0): 45,\n",
       " (\"y'all\", 1.0): 3,\n",
       " ('yeah', 1.0): 30,\n",
       " ('suppos', 1.0): 6,\n",
       " ('lol', 1.0): 48,\n",
       " ('chat', 1.0): 9,\n",
       " ('bit', 1.0): 16,\n",
       " ('youth', 1.0): 14,\n",
       " ('üíÖüèΩ', 1.0): 1,\n",
       " ('üíã', 1.0): 2,\n",
       " ('seen', 1.0): 6,\n",
       " ('year', 1.0): 33,\n",
       " ('rest', 1.0): 9,\n",
       " ('goe', 1.0): 4,\n",
       " ('quickli', 1.0): 3,\n",
       " ('bed', 1.0): 8,\n",
       " ('music', 1.0): 15,\n",
       " ('fix', 1.0): 6,\n",
       " ('dream', 1.0): 17,\n",
       " ('spiritu', 1.0): 1,\n",
       " ('ritual', 1.0): 1,\n",
       " ('festiv', 1.0): 7,\n",
       " ('n√©pal', 1.0): 1,\n",
       " ('begin', 1.0): 4,\n",
       " ('line-up', 1.0): 4,\n",
       " ('left', 1.0): 10,\n",
       " ('see', 1.0): 156,\n",
       " ('sarah', 1.0): 4,\n",
       " ('send', 1.0): 17,\n",
       " ('us', 1.0): 91,\n",
       " ('email', 1.0): 22,\n",
       " ('bitsy@bitdefender.com', 1.0): 1,\n",
       " ('asap', 1.0): 5,\n",
       " ('kik', 1.0): 16,\n",
       " ('hatessuc', 1.0): 1,\n",
       " ('32429', 1.0): 1,\n",
       " ('kikm', 1.0): 1,\n",
       " ('lgbt', 1.0): 2,\n",
       " ('tinder', 1.0): 1,\n",
       " ('nsfw', 1.0): 1,\n",
       " ('akua', 1.0): 1,\n",
       " ('cumshot', 1.0): 1,\n",
       " ('come', 1.0): 63,\n",
       " ('hous', 1.0): 5,\n",
       " ('nsn_supplement', 1.0): 1,\n",
       " ('effect', 1.0): 2,\n",
       " ('press', 1.0): 1,\n",
       " ('releas', 1.0): 11,\n",
       " ('distribut', 1.0): 1,\n",
       " ('result', 1.0): 2,\n",
       " ('link', 1.0): 13,\n",
       " ('remov', 1.0): 3,\n",
       " ('pressreleas', 1.0): 1,\n",
       " ('newsdistribut', 1.0): 1,\n",
       " ('bam', 1.0): 44,\n",
       " ('bestfriend', 1.0): 50,\n",
       " ('lot', 1.0): 80,\n",
       " ('warsaw', 1.0): 44,\n",
       " ('<3', 1.0): 118,\n",
       " ('x46', 1.0): 1,\n",
       " ('everyon', 1.0): 45,\n",
       " ('watch', 1.0): 32,\n",
       " ('documentari', 1.0): 1,\n",
       " ('earthl', 1.0): 1,\n",
       " ('youtub', 1.0): 8,\n",
       " ('support', 1.0): 25,\n",
       " ('buuut', 1.0): 1,\n",
       " ('oh', 1.0): 44,\n",
       " ('look', 1.0): 109,\n",
       " ('forward', 1.0): 20,\n",
       " ('visit', 1.0): 25,\n",
       " ('next', 1.0): 37,\n",
       " ('letsgetmessi', 1.0): 1,\n",
       " ('jo', 1.0): 1,\n",
       " ('make', 1.0): 69,\n",
       " ('feel', 1.0): 33,\n",
       " ('better', 1.0): 40,\n",
       " ('never', 1.0): 31,\n",
       " ('anyon', 1.0): 7,\n",
       " ('kpop', 1.0): 1,\n",
       " ('flesh', 1.0): 1,\n",
       " ('good', 1.0): 191,\n",
       " ('girl', 1.0): 34,\n",
       " ('best', 1.0): 49,\n",
       " ('wish', 1.0): 29,\n",
       " ('reason', 1.0): 10,\n",
       " ('epic', 1.0): 1,\n",
       " ('soundtrack', 1.0): 1,\n",
       " ('shout', 1.0): 11,\n",
       " ('ad', 1.0): 10,\n",
       " ('video', 1.0): 29,\n",
       " ('playlist', 1.0): 5,\n",
       " ('would', 1.0): 70,\n",
       " ('dear', 1.0): 15,\n",
       " ('jordan', 1.0): 1,\n",
       " ('okay', 1.0): 31,\n",
       " ('fake', 1.0): 1,\n",
       " ('gameplay', 1.0): 1,\n",
       " (';)', 1.0): 22,\n",
       " ('haha', 1.0): 44,\n",
       " ('im', 1.0): 38,\n",
       " ('kid', 1.0): 13,\n",
       " ('stuff', 1.0): 11,\n",
       " ('exactli', 1.0): 5,\n",
       " ('product', 1.0): 11,\n",
       " ('line', 1.0): 6,\n",
       " ('etsi', 1.0): 1,\n",
       " ('shop', 1.0): 12,\n",
       " ('check', 1.0): 38,\n",
       " ('vacat', 1.0): 5,\n",
       " ('recharg', 1.0): 1,\n",
       " ('normal', 1.0): 5,\n",
       " ('charger', 1.0): 2,\n",
       " ('asleep', 1.0): 7,\n",
       " ('talk', 1.0): 37,\n",
       " ('sooo', 1.0): 6,\n",
       " ('someon', 1.0): 29,\n",
       " ('text', 1.0): 12,\n",
       " ('ye', 1.0): 60,\n",
       " ('bet', 1.0): 6,\n",
       " ('fit', 1.0): 2,\n",
       " ('hear', 1.0): 24,\n",
       " ('speech', 1.0): 1,\n",
       " ('piti', 1.0): 2,\n",
       " ('green', 1.0): 2,\n",
       " ('garden', 1.0): 5,\n",
       " ('midnight', 1.0): 1,\n",
       " ('sun', 1.0): 6,\n",
       " ('beauti', 1.0): 45,\n",
       " ('canal', 1.0): 1,\n",
       " ('dasvidaniya', 1.0): 1,\n",
       " ('till', 1.0): 16,\n",
       " ('scout', 1.0): 1,\n",
       " ('sg', 1.0): 1,\n",
       " ('futur', 1.0): 9,\n",
       " ('wlan', 1.0): 1,\n",
       " ('pro', 1.0): 4,\n",
       " ('confer', 1.0): 1,\n",
       " ('asia', 1.0): 1,\n",
       " ('chang', 1.0): 20,\n",
       " ('lollipop', 1.0): 1,\n",
       " ('üç≠', 1.0): 1,\n",
       " ('nez', 1.0): 1,\n",
       " ('agnezmo', 1.0): 1,\n",
       " ('oley', 1.0): 1,\n",
       " ('mama', 1.0): 1,\n",
       " ('stand', 1.0): 6,\n",
       " ('stronger', 1.0): 1,\n",
       " ('god', 1.0): 14,\n",
       " ('misti', 1.0): 1,\n",
       " ('babi', 1.0): 17,\n",
       " ('cute', 1.0): 21,\n",
       " ('woohoo', 1.0): 3,\n",
       " (\"can't\", 1.0): 31,\n",
       " ('sign', 1.0): 9,\n",
       " ('yet', 1.0): 12,\n",
       " ('still', 1.0): 37,\n",
       " ('think', 1.0): 48,\n",
       " ('mka', 1.0): 5,\n",
       " ('liam', 1.0): 5,\n",
       " ('access', 1.0): 3,\n",
       " ('welcom', 1.0): 54,\n",
       " ('stat', 1.0): 51,\n",
       " ('arriv', 1.0): 57,\n",
       " ('1', 1.0): 60,\n",
       " ('unfollow', 1.0): 53,\n",
       " ('via', 1.0): 60,\n",
       " ('surpris', 1.0): 10,\n",
       " ('figur', 1.0): 5,\n",
       " ('happybirthdayemilybett', 1.0): 1,\n",
       " ('sweet', 1.0): 16,\n",
       " ('talent', 1.0): 4,\n",
       " ('2', 1.0): 41,\n",
       " ('plan', 1.0): 21,\n",
       " ('drain', 1.0): 1,\n",
       " ('gotta', 1.0): 4,\n",
       " ('timezon', 1.0): 1,\n",
       " ('parent', 1.0): 4,\n",
       " ('proud', 1.0): 11,\n",
       " ('least', 1.0): 14,\n",
       " ('mayb', 1.0): 17,\n",
       " ('sometim', 1.0): 11,\n",
       " ('grade', 1.0): 4,\n",
       " ('al', 1.0): 3,\n",
       " ('grand', 1.0): 4,\n",
       " ('manila_bro', 1.0): 1,\n",
       " ('chosen', 1.0): 1,\n",
       " ('let', 1.0): 57,\n",
       " ('around', 1.0): 14,\n",
       " ('..', 1.0): 100,\n",
       " ('side', 1.0): 13,\n",
       " ('world', 1.0): 23,\n",
       " ('eh', 1.0): 2,\n",
       " ('take', 1.0): 30,\n",
       " ('care', 1.0): 12,\n",
       " ('final', 1.0): 24,\n",
       " ('fuck', 1.0): 20,\n",
       " ('weekend', 1.0): 61,\n",
       " ('real', 1.0): 18,\n",
       " ('x45', 1.0): 1,\n",
       " ('join', 1.0): 21,\n",
       " ('hushedcallwithfraydo', 1.0): 1,\n",
       " ('gift', 1.0): 7,\n",
       " ('yeahhh', 1.0): 1,\n",
       " ('hushedpinwithsammi', 1.0): 2,\n",
       " ('event', 1.0): 7,\n",
       " ('might', 1.0): 21,\n",
       " ('luv', 1.0): 4,\n",
       " ('realli', 1.0): 66,\n",
       " ('appreci', 1.0): 28,\n",
       " ('share', 1.0): 41,\n",
       " ('wow', 1.0): 14,\n",
       " ('tom', 1.0): 5,\n",
       " ('gym', 1.0): 3,\n",
       " ('monday', 1.0): 7,\n",
       " ('invit', 1.0): 15,\n",
       " ('scope', 1.0): 5,\n",
       " ('friend', 1.0): 40,\n",
       " ('nude', 1.0): 1,\n",
       " ('sleep', 1.0): 35,\n",
       " ('birthday', 1.0): 53,\n",
       " ('want', 1.0): 69,\n",
       " ('t-shirt', 1.0): 2,\n",
       " ('cool', 1.0): 29,\n",
       " ('haw', 1.0): 1,\n",
       " ('phela', 1.0): 1,\n",
       " ('mom', 1.0): 7,\n",
       " ('obvious', 1.0): 1,\n",
       " ('princ', 1.0): 1,\n",
       " ('charm', 1.0): 1,\n",
       " ('stage', 1.0): 2,\n",
       " ('luck', 1.0): 26,\n",
       " ('tyler', 1.0): 1,\n",
       " ('hipster', 1.0): 1,\n",
       " ('glass', 1.0): 3,\n",
       " ('marti', 1.0): 2,\n",
       " ('glad', 1.0): 41,\n",
       " ('done', 1.0): 40,\n",
       " ('afternoon', 1.0): 7,\n",
       " ('read', 1.0): 27,\n",
       " ('kahfi', 1.0): 1,\n",
       " ('finish', 1.0): 15,\n",
       " ('ohmyg', 1.0): 1,\n",
       " ('yaya', 1.0): 3,\n",
       " ('dub', 1.0): 1,\n",
       " ('stalk', 1.0): 2,\n",
       " ('ig', 1.0): 3,\n",
       " ('gondooo', 1.0): 1,\n",
       " ('moo', 1.0): 2,\n",
       " ('tologooo', 1.0): 1,\n",
       " ('becom', 1.0): 8,\n",
       " ('detail', 1.0): 8,\n",
       " ('zzz', 1.0): 1,\n",
       " ('xx', 1.0): 33,\n",
       " ('physiotherapi', 1.0): 1,\n",
       " ('hashtag', 1.0): 3,\n",
       " ('üí™', 1.0): 1,\n",
       " ('monica', 1.0): 1,\n",
       " ('miss', 1.0): 17,\n",
       " ('sound', 1.0): 20,\n",
       " ('morn', 1.0): 68,\n",
       " (\"that'\", 1.0): 49,\n",
       " ('x43', 1.0): 1,\n",
       " ('definit', 1.0): 20,\n",
       " ('tri', 1.0): 34,\n",
       " ('tonight', 1.0): 15,\n",
       " ('took', 1.0): 7,\n",
       " ('advic', 1.0): 6,\n",
       " ('treviso', 1.0): 1,\n",
       " ('concert', 1.0): 23,\n",
       " ('citi', 1.0): 26,\n",
       " ('countri', 1.0): 22,\n",
       " ('start', 1.0): 56,\n",
       " ('fine', 1.0): 7,\n",
       " ('gorgeou', 1.0): 9,\n",
       " ('xo', 1.0): 2,\n",
       " ('oven', 1.0): 2,\n",
       " ('roast', 1.0): 1,\n",
       " ('garlic', 1.0): 1,\n",
       " ('oliv', 1.0): 1,\n",
       " ('oil', 1.0): 4,\n",
       " ('dri', 1.0): 4,\n",
       " ('tomato', 1.0): 1,\n",
       " ('basil', 1.0): 1,\n",
       " ('centuri', 1.0): 1,\n",
       " ('tuna', 1.0): 1,\n",
       " ('right', 1.0): 38,\n",
       " ('back', 1.0): 74,\n",
       " ('atchya', 1.0): 1,\n",
       " ('even', 1.0): 26,\n",
       " ('almost', 1.0): 8,\n",
       " ('chanc', 1.0): 3,\n",
       " ('cheer', 1.0): 17,\n",
       " ('po', 1.0): 3,\n",
       " ('ice', 1.0): 6,\n",
       " ('cream', 1.0): 6,\n",
       " ('agre', 1.0): 13,\n",
       " ('100', 1.0): 6,\n",
       " ('heheheh', 1.0): 2,\n",
       " ('that', 1.0): 10,\n",
       " ('point', 1.0): 11,\n",
       " ('stay', 1.0): 20,\n",
       " ('home', 1.0): 20,\n",
       " ('soon', 1.0): 38,\n",
       " ('promis', 1.0): 4,\n",
       " ('web', 1.0): 4,\n",
       " ('whatsapp', 1.0): 3,\n",
       " ('volta', 1.0): 1,\n",
       " ('funcionar', 1.0): 1,\n",
       " ('com', 1.0): 2,\n",
       " ('iphon', 1.0): 7,\n",
       " ('jailbroken', 1.0): 1,\n",
       " ('later', 1.0): 11,\n",
       " ('34', 1.0): 3,\n",
       " ('min', 1.0): 7,\n",
       " ('leia', 1.0): 1,\n",
       " ('appear', 1.0): 3,\n",
       " ('hologram', 1.0): 1,\n",
       " ('r2d2', 1.0): 1,\n",
       " ('w', 1.0): 16,\n",
       " ('messag', 1.0): 9,\n",
       " ('obi', 1.0): 1,\n",
       " ('wan', 1.0): 1,\n",
       " ('sit', 1.0): 7,\n",
       " ('luke', 1.0): 4,\n",
       " ('inter', 1.0): 1,\n",
       " ('3', 1.0): 25,\n",
       " ('ucl', 1.0): 1,\n",
       " ('arsen', 1.0): 2,\n",
       " ('small', 1.0): 1,\n",
       " ('team', 1.0): 24,\n",
       " ('pass', 1.0): 10,\n",
       " ('üöÇ', 1.0): 1,\n",
       " ('dewsburi', 1.0): 2,\n",
       " ('railway', 1.0): 1,\n",
       " ('station', 1.0): 4,\n",
       " ('dew', 1.0): 1,\n",
       " ('west', 1.0): 1,\n",
       " ('yorkshir', 1.0): 2,\n",
       " ('430', 1.0): 1,\n",
       " ('smh', 1.0): 2,\n",
       " ('9:25', 1.0): 1,\n",
       " ('live', 1.0): 21,\n",
       " ('strang', 1.0): 4,\n",
       " ('imagin', 1.0): 5,\n",
       " ('megan', 1.0): 1,\n",
       " ('masaantoday', 1.0): 4,\n",
       " ('a4', 1.0): 3,\n",
       " ('shweta', 1.0): 1,\n",
       " ('tripathi', 1.0): 1,\n",
       " ('5', 1.0): 15,\n",
       " ('20', 1.0): 5,\n",
       " ('kurta', 1.0): 3,\n",
       " ('half', 1.0): 6,\n",
       " ('number', 1.0): 11,\n",
       " ('wsalelov', 1.0): 14,\n",
       " ('ah', 1.0): 12,\n",
       " ('larri', 1.0): 3,\n",
       " ('anyway', 1.0): 14,\n",
       " ('kinda', 1.0): 12,\n",
       " ('goood', 1.0): 1,\n",
       " ('life', 1.0): 36,\n",
       " ('enn', 1.0): 1,\n",
       " ('could', 1.0): 25,\n",
       " ('warmup', 1.0): 1,\n",
       " ('15th', 1.0): 2,\n",
       " ('bath', 1.0): 6,\n",
       " ('dum', 1.0): 2,\n",
       " ('andar', 1.0): 1,\n",
       " ('ram', 1.0): 1,\n",
       " ('sampath', 1.0): 1,\n",
       " ('sona', 1.0): 1,\n",
       " ('mohapatra', 1.0): 1,\n",
       " ('samantha', 1.0): 1,\n",
       " ('edward', 1.0): 1,\n",
       " ('mein', 1.0): 1,\n",
       " ('tulan', 1.0): 1,\n",
       " ('razi', 1.0): 2,\n",
       " ('wah', 1.0): 2,\n",
       " ('josh', 1.0): 1,\n",
       " ('alway', 1.0): 48,\n",
       " ('smile', 1.0): 47,\n",
       " ('pictur', 1.0): 7,\n",
       " ('16.20', 1.0): 1,\n",
       " ('giveitup', 1.0): 1,\n",
       " ('given', 1.0): 3,\n",
       " ('ga', 1.0): 3,\n",
       " ('subsidi', 1.0): 1,\n",
       " ('initi', 1.0): 2,\n",
       " ('propos', 1.0): 3,\n",
       " ('delight', 1.0): 4,\n",
       " ('yesterday', 1.0): 4,\n",
       " ('x42', 1.0): 1,\n",
       " ('lmaoo', 1.0): 2,\n",
       " ('song', 1.0): 16,\n",
       " ('ever', 1.0): 19,\n",
       " ('shall', 1.0): 5,\n",
       " ('littl', 1.0): 29,\n",
       " ('throwback', 1.0): 3,\n",
       " ('outli', 1.0): 1,\n",
       " ('island', 1.0): 2,\n",
       " ('cheung', 1.0): 1,\n",
       " ('chau', 1.0): 1,\n",
       " ('mui', 1.0): 1,\n",
       " ('wo', 1.0): 1,\n",
       " ('total', 1.0): 5,\n",
       " ('differ', 1.0): 10,\n",
       " ('kfckitchentour', 1.0): 2,\n",
       " ('kitchen', 1.0): 3,\n",
       " ('clean', 1.0): 1,\n",
       " ('cusp', 1.0): 1,\n",
       " ('test', 1.0): 7,\n",
       " ('water', 1.0): 7,\n",
       " ('reward', 1.0): 1,\n",
       " ('arummzz', 1.0): 2,\n",
       " (\"let'\", 1.0): 18,\n",
       " ('drive', 1.0): 9,\n",
       " ('travel', 1.0): 19,\n",
       " ('yogyakarta', 1.0): 3,\n",
       " ('jeep', 1.0): 3,\n",
       " ('indonesia', 1.0): 3,\n",
       " ('instamood', 1.0): 3,\n",
       " ('wanna', 1.0): 23,\n",
       " ('skype', 1.0): 3,\n",
       " ('may', 1.0): 16,\n",
       " ('nice', 1.0): 70,\n",
       " ('friendli', 1.0): 1,\n",
       " ('pretend', 1.0): 2,\n",
       " ('film', 1.0): 8,\n",
       " ('congratul', 1.0): 9,\n",
       " ('winner', 1.0): 3,\n",
       " ('cheesydelight', 1.0): 1,\n",
       " ('contest', 1.0): 5,\n",
       " ('address', 1.0): 8,\n",
       " ('guy', 1.0): 48,\n",
       " ('market', 1.0): 5,\n",
       " ('24/7', 1.0): 1,\n",
       " ('14', 1.0): 1,\n",
       " ('hour', 1.0): 24,\n",
       " ('leav', 1.0): 11,\n",
       " ('without', 1.0): 9,\n",
       " ('delay', 1.0): 1,\n",
       " ('actual', 1.0): 13,\n",
       " ('easi', 1.0): 7,\n",
       " ('guess', 1.0): 8,\n",
       " ('train', 1.0): 7,\n",
       " ('wd', 1.0): 1,\n",
       " ('shift', 1.0): 4,\n",
       " ('engin', 1.0): 1,\n",
       " ('etc', 1.0): 2,\n",
       " ('sunburn', 1.0): 1,\n",
       " ('peel', 1.0): 2,\n",
       " ('blog', 1.0): 27,\n",
       " ('huge', 1.0): 9,\n",
       " ('warm', 1.0): 4,\n",
       " ('‚òÜ', 1.0): 3,\n",
       " ('complet', 1.0): 10,\n",
       " ('triangl', 1.0): 2,\n",
       " ('northern', 1.0): 1,\n",
       " ('ireland', 1.0): 2,\n",
       " ('sight', 1.0): 1,\n",
       " ('smthng', 1.0): 2,\n",
       " ('fr', 1.0): 3,\n",
       " ('hug', 1.0): 11,\n",
       " ('xoxo', 1.0): 3,\n",
       " ('uu', 1.0): 1,\n",
       " ('jaann', 1.0): 1,\n",
       " ('topnewfollow', 1.0): 2,\n",
       " ('connect', 1.0): 13,\n",
       " ('wonder', 1.0): 26,\n",
       " ('made', 1.0): 38,\n",
       " ('fluffi', 1.0): 1,\n",
       " ('insid', 1.0): 7,\n",
       " ('pirouett', 1.0): 1,\n",
       " ('moos', 1.0): 1,\n",
       " ('trip', 1.0): 12,\n",
       " ('philli', 1.0): 1,\n",
       " ('decemb', 1.0): 2,\n",
       " ('dude', 1.0): 6,\n",
       " ('x41', 1.0): 1,\n",
       " ('question', 1.0): 15,\n",
       " ('flaw', 1.0): 1,\n",
       " ('pain', 1.0): 8,\n",
       " ('negat', 1.0): 1,\n",
       " ('strength', 1.0): 2,\n",
       " ('went', 1.0): 10,\n",
       " ('solo', 1.0): 4,\n",
       " ('move', 1.0): 9,\n",
       " ('fav', 1.0): 11,\n",
       " ('nirvana', 1.0): 1,\n",
       " ('smell', 1.0): 2,\n",
       " ('teen', 1.0): 3,\n",
       " ('spirit', 1.0): 1,\n",
       " ('rip', 1.0): 3,\n",
       " ('ami', 1.0): 4,\n",
       " ('winehous', 1.0): 1,\n",
       " ('coupl', 1.0): 5,\n",
       " ('tomhiddleston', 1.0): 1,\n",
       " ('elizabetholsen', 1.0): 1,\n",
       " ('yaytheylookgreat', 1.0): 1,\n",
       " ('goodnight', 1.0): 18,\n",
       " ('vid', 1.0): 8,\n",
       " ('wake', 1.0): 10,\n",
       " ('gonna', 1.0): 16,\n",
       " ('shoot', 1.0): 5,\n",
       " ('itti', 1.0): 2,\n",
       " ('bitti', 1.0): 2,\n",
       " ('teeni', 1.0): 2,\n",
       " ('bikini', 1.0): 3,\n",
       " ('much', 1.0): 73,\n",
       " ('4th', 1.0): 4,\n",
       " ('togeth', 1.0): 6,\n",
       " ('end', 1.0): 13,\n",
       " ('xfile', 1.0): 1,\n",
       " ('content', 1.0): 3,\n",
       " ('rain', 1.0): 18,\n",
       " ('fabul', 1.0): 4,\n",
       " ('fantast', 1.0): 8,\n",
       " ('‚ô°', 1.0): 12,\n",
       " ('jb', 1.0): 1,\n",
       " ('forev', 1.0): 5,\n",
       " ('belieb', 1.0): 3,\n",
       " ('nighti', 1.0): 1,\n",
       " ('bug', 1.0): 2,\n",
       " ('bite', 1.0): 1,\n",
       " ('bracelet', 1.0): 2,\n",
       " ('idea', 1.0): 23,\n",
       " ('foundri', 1.0): 1,\n",
       " ('game', 1.0): 23,\n",
       " ('sens', 1.0): 6,\n",
       " ('pic', 1.0): 21,\n",
       " ('ef', 1.0): 1,\n",
       " ('phone', 1.0): 16,\n",
       " ('woot', 1.0): 2,\n",
       " ('derek', 1.0): 1,\n",
       " ('use', 1.0): 32,\n",
       " ('parkshar', 1.0): 1,\n",
       " ('gloucestershir', 1.0): 1,\n",
       " ('aaaahhh', 1.0): 1,\n",
       " ('man', 1.0): 16,\n",
       " ('traffic', 1.0): 2,\n",
       " ('stress', 1.0): 4,\n",
       " ('reliev', 1.0): 1,\n",
       " (\"how'r\", 1.0): 1,\n",
       " ('arbeloa', 1.0): 1,\n",
       " ('turn', 1.0): 13,\n",
       " ('17', 1.0): 2,\n",
       " ('omg', 1.0): 13,\n",
       " ('say', 1.0): 43,\n",
       " ('europ', 1.0): 1,\n",
       " ('rise', 1.0): 2,\n",
       " ('find', 1.0): 20,\n",
       " ('hard', 1.0): 9,\n",
       " ('believ', 1.0): 7,\n",
       " ('uncount', 1.0): 1,\n",
       " ('coz', 1.0): 2,\n",
       " ('unlimit', 1.0): 1,\n",
       " ('cours', 1.0): 11,\n",
       " ('teamposit', 1.0): 1,\n",
       " ('aldub', 1.0): 2,\n",
       " ('‚òï', 1.0): 3,\n",
       " ('rita', 1.0): 2,\n",
       " ('info', 1.0): 10,\n",
       " ('way', 1.0): 34,\n",
       " ('boy', 1.0): 13,\n",
       " ('x40', 1.0): 1,\n",
       " ('true', 1.0): 19,\n",
       " ('sethi', 1.0): 2,\n",
       " ('high', 1.0): 6,\n",
       " ('exe', 1.0): 1,\n",
       " ('skeem', 1.0): 1,\n",
       " ('saam', 1.0): 1,\n",
       " ('peopl', 1.0): 42,\n",
       " ('polit', 1.0): 2,\n",
       " ('izzat', 1.0): 1,\n",
       " ('wese', 1.0): 1,\n",
       " ('trust', 1.0): 7,\n",
       " ('khawateen', 1.0): 1,\n",
       " ('k', 1.0): 8,\n",
       " ('sath', 1.0): 2,\n",
       " ('mana', 1.0): 1,\n",
       " ('kar', 1.0): 1,\n",
       " ('deya', 1.0): 1,\n",
       " ('sort', 1.0): 7,\n",
       " ('smart', 1.0): 5,\n",
       " ('hair', 1.0): 7,\n",
       " ('tbh', 1.0): 5,\n",
       " ('jacob', 1.0): 2,\n",
       " ('g', 1.0): 7,\n",
       " ('upgrad', 1.0): 2,\n",
       " ('tee', 1.0): 2,\n",
       " ('famili', 1.0): 14,\n",
       " ('person', 1.0): 14,\n",
       " ('two', 1.0): 15,\n",
       " ('convers', 1.0): 6,\n",
       " ('onlin', 1.0): 4,\n",
       " ('mclaren', 1.0): 1,\n",
       " ('fridayfeel', 1.0): 5,\n",
       " ('tgif', 1.0): 8,\n",
       " ('squar', 1.0): 1,\n",
       " ('enix', 1.0): 1,\n",
       " ('bissmillah', 1.0): 1,\n",
       " ('ya', 1.0): 19,\n",
       " ('allah', 1.0): 3,\n",
       " ('socent', 1.0): 1,\n",
       " ('startup', 1.0): 2,\n",
       " ('drop', 1.0): 9,\n",
       " ('your', 1.0): 3,\n",
       " ('arnd', 1.0): 1,\n",
       " ('town', 1.0): 3,\n",
       " ('basic', 1.0): 4,\n",
       " ('piss', 1.0): 2,\n",
       " ('cup', 1.0): 4,\n",
       " ('also', 1.0): 28,\n",
       " ('terribl', 1.0): 2,\n",
       " ('complic', 1.0): 1,\n",
       " ('discuss', 1.0): 2,\n",
       " ('snapchat', 1.0): 31,\n",
       " ('lynettelow', 1.0): 1,\n",
       " ('kikmenow', 1.0): 2,\n",
       " ('snapm', 1.0): 1,\n",
       " ('hot', 1.0): 20,\n",
       " ('amazon', 1.0): 1,\n",
       " ('kikmeguy', 1.0): 2,\n",
       " ('defin', 1.0): 2,\n",
       " ('grow', 1.0): 6,\n",
       " ('sport', 1.0): 4,\n",
       " ('rt', 1.0): 9,\n",
       " ('rakyat', 1.0): 1,\n",
       " ('write', 1.0): 11,\n",
       " ('sinc', 1.0): 11,\n",
       " ('mention', 1.0): 18,\n",
       " ('fli', 1.0): 5,\n",
       " ('fish', 1.0): 3,\n",
       " ('promot', 1.0): 3,\n",
       " ('post', 1.0): 16,\n",
       " ('cyber', 1.0): 1,\n",
       " ('ourdaughtersourprid', 1.0): 3,\n",
       " ('mypapamyprid', 1.0): 2,\n",
       " ('papa', 1.0): 1,\n",
       " ('coach', 1.0): 2,\n",
       " ('posit', 1.0): 3,\n",
       " ('kha', 1.0): 1,\n",
       " ('atleast', 1.0): 2,\n",
       " ('x39', 1.0): 1,\n",
       " ('mango', 1.0): 1,\n",
       " (\"lassi'\", 1.0): 1,\n",
       " (\"monty'\", 1.0): 1,\n",
       " ('marvel', 1.0): 2,\n",
       " ('though', 1.0): 16,\n",
       " ('suspect', 1.0): 3,\n",
       " ('meant', 1.0): 2,\n",
       " ('24', 1.0): 3,\n",
       " ('hr', 1.0): 2,\n",
       " ('touch', 1.0): 7,\n",
       " ('kepler', 1.0): 3,\n",
       " ('452b', 1.0): 4,\n",
       " ('chalna', 1.0): 1,\n",
       " ('hai', 1.0): 7,\n",
       " ('thankyou', 1.0): 12,\n",
       " ('hazel', 1.0): 1,\n",
       " ('food', 1.0): 6,\n",
       " ('brooklyn', 1.0): 1,\n",
       " ('pta', 1.0): 2,\n",
       " ('awak', 1.0): 8,\n",
       " ('okayi', 1.0): 2,\n",
       " ('awww', 1.0): 12,\n",
       " ('ha', 1.0): 18,\n",
       " ('doc', 1.0): 1,\n",
       " ('splendid', 1.0): 1,\n",
       " ('spam', 1.0): 1,\n",
       " ('folder', 1.0): 1,\n",
       " ('amount', 1.0): 1,\n",
       " ('nigeria', 1.0): 1,\n",
       " ('claim', 1.0): 1,\n",
       " ('rted', 1.0): 1,\n",
       " ('leg', 1.0): 3,\n",
       " ('hurt', 1.0): 4,\n",
       " ('bad', 1.0): 14,\n",
       " ('mine', 1.0): 11,\n",
       " ('saturday', 1.0): 5,\n",
       " ('thaaank', 1.0): 1,\n",
       " ('puhon', 1.0): 1,\n",
       " ('happinesss', 1.0): 1,\n",
       " ('tnc', 1.0): 1,\n",
       " ('prior', 1.0): 1,\n",
       " ('notif', 1.0): 2,\n",
       " ('fat', 1.0): 1,\n",
       " ('co', 1.0): 1,\n",
       " ('probabl', 1.0): 7,\n",
       " ('ate', 1.0): 4,\n",
       " ('yuna', 1.0): 2,\n",
       " ('tamesid', 1.0): 1,\n",
       " ('¬¥', 1.0): 3,\n",
       " ('googl', 1.0): 5,\n",
       " ('account', 1.0): 17,\n",
       " ('scouser', 1.0): 1,\n",
       " ('everyth', 1.0): 10,\n",
       " ('zoe', 1.0): 1,\n",
       " ('mate', 1.0): 5,\n",
       " ('liter', 1.0): 5,\n",
       " ('samee', 1.0): 1,\n",
       " ('edgar', 1.0): 1,\n",
       " ('updat', 1.0): 12,\n",
       " ('log', 1.0): 3,\n",
       " ('bring', 1.0): 12,\n",
       " ('abe', 1.0): 1,\n",
       " ('meet', 1.0): 26,\n",
       " ('x38', 1.0): 1,\n",
       " ('sigh', 1.0): 3,\n",
       " ('dreamili', 1.0): 1,\n",
       " ('pout', 1.0): 1,\n",
       " ('eye', 1.0): 12,\n",
       " ('quacketyquack', 1.0): 6,\n",
       " ('funni', 1.0): 15,\n",
       " ('happen', 1.0): 13,\n",
       " ('phil', 1.0): 1,\n",
       " ('em', 1.0): 2,\n",
       " ('del', 1.0): 1,\n",
       " ('rodder', 1.0): 1,\n",
       " ('els', 1.0): 8,\n",
       " ('play', 1.0): 37,\n",
       " ('newest', 1.0): 1,\n",
       " ('gamejam', 1.0): 1,\n",
       " ('irish', 1.0): 2,\n",
       " ('literatur', 1.0): 2,\n",
       " ('inaccess', 1.0): 2,\n",
       " (\"kareena'\", 1.0): 2,\n",
       " ('fan', 1.0): 21,\n",
       " ('brain', 1.0): 10,\n",
       " ('dot', 1.0): 8,\n",
       " ('braindot', 1.0): 8,\n",
       " ('fair', 1.0): 4,\n",
       " ('rush', 1.0): 1,\n",
       " ('either', 1.0): 10,\n",
       " ('brandi', 1.0): 1,\n",
       " ('18', 1.0): 5,\n",
       " ('carniv', 1.0): 1,\n",
       " ('men', 1.0): 8,\n",
       " ('put', 1.0): 11,\n",
       " ('mask', 1.0): 2,\n",
       " ('xavier', 1.0): 1,\n",
       " ('forneret', 1.0): 1,\n",
       " ('jennif', 1.0): 1,\n",
       " ('site', 1.0): 7,\n",
       " ('free', 1.0): 31,\n",
       " ('50.000', 1.0): 3,\n",
       " ('8', 1.0): 10,\n",
       " ('ball', 1.0): 7,\n",
       " ('pool', 1.0): 5,\n",
       " ('coin', 1.0): 5,\n",
       " ('edit', 1.0): 6,\n",
       " ('trish', 1.0): 1,\n",
       " ('‚ô•', 1.0): 13,\n",
       " ('grate', 1.0): 5,\n",
       " ('three', 1.0): 8,\n",
       " ('comment', 1.0): 7,\n",
       " ('wakeup', 1.0): 1,\n",
       " ('besid', 1.0): 2,\n",
       " ('dirti', 1.0): 2,\n",
       " ('sex', 1.0): 4,\n",
       " ('lmaooo', 1.0): 1,\n",
       " ('üò§', 1.0): 2,\n",
       " ('loui', 1.0): 4,\n",
       " ('throw', 1.0): 3,\n",
       " ('caus', 1.0): 11,\n",
       " ('inspir', 1.0): 6,\n",
       " ('ff', 1.0): 40,\n",
       " ('twoof', 1.0): 3,\n",
       " ('gr8', 1.0): 1,\n",
       " ('wkend', 1.0): 3,\n",
       " ('kind', 1.0): 22,\n",
       " ('exhaust', 1.0): 2,\n",
       " ('word', 1.0): 17,\n",
       " ('cheltenham', 1.0): 1,\n",
       " ('area', 1.0): 4,\n",
       " ('kale', 1.0): 1,\n",
       " ('crisp', 1.0): 1,\n",
       " ('ruin', 1.0): 5,\n",
       " ('x37', 1.0): 1,\n",
       " ('open', 1.0): 12,\n",
       " ('worldwid', 1.0): 2,\n",
       " ('outta', 1.0): 1,\n",
       " ('sfvbeta', 1.0): 1,\n",
       " ('vantast', 1.0): 1,\n",
       " ('xcylin', 1.0): 1,\n",
       " ('bundl', 1.0): 1,\n",
       " ('show', 1.0): 20,\n",
       " ('internet', 1.0): 2,\n",
       " ('price', 1.0): 3,\n",
       " ('realisticli', 1.0): 1,\n",
       " ('pay', 1.0): 8,\n",
       " ('net', 1.0): 1,\n",
       " ('educ', 1.0): 1,\n",
       " ('power', 1.0): 6,\n",
       " ('weapon', 1.0): 1,\n",
       " ('nelson', 1.0): 1,\n",
       " ('mandela', 1.0): 1,\n",
       " ('recent', 1.0): 8,\n",
       " ('j', 1.0): 2,\n",
       " ('chenab', 1.0): 1,\n",
       " ('flow', 1.0): 5,\n",
       " ('pakistan', 1.0): 1,\n",
       " ('incredibleindia', 1.0): 1,\n",
       " ('teenchoic', 1.0): 7,\n",
       " ('choiceinternationalartist', 1.0): 7,\n",
       " ('superjunior', 1.0): 7,\n",
       " ('caught', 1.0): 4,\n",
       " ('first', 1.0): 41,\n",
       " ('salmon', 1.0): 1,\n",
       " ('super-blend', 1.0): 1,\n",
       " ('project', 1.0): 6,\n",
       " ('youth@bipolaruk.org.uk', 1.0): 1,\n",
       " ('awesom', 1.0): 35,\n",
       " ('stream', 1.0): 12,\n",
       " ('alma', 1.0): 1,\n",
       " ('mater', 1.0): 1,\n",
       " ('highschoolday', 1.0): 1,\n",
       " ('clientvisit', 1.0): 1,\n",
       " ('faith', 1.0): 3,\n",
       " ('christian', 1.0): 1,\n",
       " ('school', 1.0): 9,\n",
       " ('lizaminnelli', 1.0): 1,\n",
       " ('upcom', 1.0): 2,\n",
       " ('uk', 1.0): 4,\n",
       " ('üòÑ', 1.0): 3,\n",
       " ('singl', 1.0): 4,\n",
       " ('hill', 1.0): 4,\n",
       " ('everi', 1.0): 23,\n",
       " ('beat', 1.0): 7,\n",
       " ('wrong', 1.0): 9,\n",
       " ('readi', 1.0): 22,\n",
       " ('natur', 1.0): 1,\n",
       " ('pefumeri', 1.0): 1,\n",
       " ('workshop', 1.0): 2,\n",
       " ('neal', 1.0): 1,\n",
       " ('yard', 1.0): 1,\n",
       " ('covent', 1.0): 1,\n",
       " ('tomorrow', 1.0): 31,\n",
       " ('fback', 1.0): 26,\n",
       " ('indo', 1.0): 1,\n",
       " ('harmo', 1.0): 1,\n",
       " ('americano', 1.0): 1,\n",
       " ('rememb', 1.0): 9,\n",
       " ('aww', 1.0): 8,\n",
       " ('head', 1.0): 12,\n",
       " ('saw', 1.0): 16,\n",
       " ('dark', 1.0): 5,\n",
       " ('handshom', 1.0): 1,\n",
       " ('juga', 1.0): 1,\n",
       " ('hurray', 1.0): 1,\n",
       " ...}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd534c39",
   "metadata": {},
   "source": [
    "## Modelagem Preditiva\n",
    "\n",
    "Usaremos o algoritmo de Regress√£o Log√≠stica para classifica√ß√£o dos tweets em positivos ou negativos. \n",
    "\n",
    "Vamos construir cada etapa matem√°tica desse algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af6f91c",
   "metadata": {},
   "source": [
    "### Parte 1:  Matem√°tica da Fun√ß√£o Sigm√≥ide\n",
    "\n",
    "A fun√ß√£o sigm√≥ide √© uma fun√ß√£o de ativa√ß√£o comumente usada em redes neurais. A fun√ß√£o sigm√≥ide √© definida como: \n",
    "\n",
    "$$ h(z) = \\frac{1}{1+\\exp^{-z}} $$\n",
    "\n",
    "Ela tem a forma de uma curva S, como mostrado abaixo:\n",
    "\n",
    "![title](imagens/sigmoid.png)\n",
    "\n",
    "A fun√ß√£o sigm√≥ide tem a seguintes propriedades:\n",
    "\n",
    "O valor de sa√≠da da fun√ß√£o sigm√≥ide est√° sempre entre 0 e 1. Isso torna a fun√ß√£o √∫til para problemas de classifica√ß√£o bin√°ria, pois pode ser interpretada como a probabilidade de um determinado exemplo pertencer √† classe positiva.\n",
    "\n",
    "A fun√ß√£o sigm√≥ide √© deriv√°vel em todos os pontos, o que a torna √∫til para o treinamento de redes neurais.\n",
    "\n",
    "A fun√ß√£o sigm√≥ide tem um gradiente muito pequeno para valores de entrada muito grandes ou muito pequenos. Isso pode causar problemas durante o treinamento da rede neural, pois pode levar ao \"estouro do gradiente\", um problema em que o gradiente fica muito grande e a rede neural deixa de aprender de maneira eficiente.\n",
    "\n",
    "Apesar desses problemas, a fun√ß√£o sigm√≥ide ainda √© usada em alguns casos, especialmente em problemas de classifica√ß√£o bin√°ria. No entanto, outras fun√ß√µes de ativa√ß√£o, como a ReLU e a tangente hiperb√≥lica, s√£o mais comumente usadas em redes neurais profundas devido ao seu desempenho melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d80f75",
   "metadata": {},
   "source": [
    "Refer√™ncia:\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a43405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o sigm√≥ide\n",
    "def sigmoid(z): \n",
    "\n",
    "    # Calcula o sigm√≥ide de z\n",
    "    h = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ecea7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7310585786300049"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testando a fun√ß√£o\n",
    "sigmoid(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3473f087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRETO!\n"
     ]
    }
   ],
   "source": [
    "# Testando a fun√ß√£o\n",
    "if (sigmoid(1) == 0.7310585786300049):\n",
    "    print('CORRETO!')\n",
    "else:\n",
    "    print('INCORRETO!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "310ffd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9805449154318069"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testando a fun√ß√£o\n",
    "sigmoid(3.92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "efa3a104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCORRETO!\n"
     ]
    }
   ],
   "source": [
    "# Testando a fun√ß√£o\n",
    "if (sigmoid(3.92) == 0.91):\n",
    "    print('CORRETO!')\n",
    "else:\n",
    "    print('INCORRETO!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79503187",
   "metadata": {},
   "source": [
    "### Parte 2: Matem√°tica da Regress√£o Log√≠stica com a Fun√ß√£o Sigm√≥ide\n",
    "\n",
    "A regress√£o log√≠stica √© um modelo de aprendizado supervisionado usado para problemas de classifica√ß√£o bin√°ria. Ela √© baseada em uma fun√ß√£o de ativa√ß√£o chamada fun√ß√£o sigm√≥ide, que √© usada para estimar a probabilidade de um exemplo pertencer √† classe positiva.\n",
    "\n",
    "A equa√ß√£o b√°sica da regress√£o log√≠stica √© dada por:\n",
    "\n",
    "p = 1 / (1 + e^(-Wx + b))\n",
    "\n",
    "Onde p √© a probabilidade de um exemplo pertencer √† classe positiva, x √© o vetor de caracter√≠sticas de entrada, W √© a matriz de pesos e b √© o vi√©s.\n",
    "\n",
    "A fun√ß√£o sigm√≥ide √© usada para transformar a sa√≠da linear da regress√£o log√≠stica em uma probabilidade. Quando a sa√≠da √© maior que 0,5, o modelo prediz que o exemplo pertence √† classe positiva, enquanto que quando a sa√≠da √© menor que 0,5, o modelo prediz que o exemplo pertence √† classe negativa.\n",
    "\n",
    "Para treinar o modelo, usamos uma fun√ß√£o de custo chamada entropia cruzada, que mede o qu√£o incorretas s√£o as previs√µes do modelo. O objetivo √© minimizar a entropia cruzada ajustando os pesos W e o vi√©s b. Isso √© geralmente feito usando a descida do gradiente, um m√©todo de otimiza√ß√£o baseado em derivadas.\n",
    "\n",
    "Uma vez treinado, o modelo pode ser usado para fazer previs√µes para novos exemplos, usando a equa√ß√£o p = 1 / (1 + e^(-Wx + b)). Se a probabilidade p for maior que 0,5, o modelo prediz que o exemplo pertence √† classe positiva, caso contr√°rio, o modelo prediz que o exemplo pertence √† classe negativa.\n",
    "\n",
    "A regress√£o log√≠stica usa uma regress√£o linear regular e aplica um sigm√≥ide √† sa√≠da da regress√£o linear.\n",
    "\n",
    "Regress√£o:\n",
    "\n",
    "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
    "\n",
    "Observe que valores $\\theta$ s√£o \"pesos\". \n",
    "\n",
    "Regress√£o Log√≠stica:\n",
    "\n",
    "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
    "\n",
    "$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n",
    "\n",
    "Vamos nos referir a 'z' como 'logits'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37071d2d",
   "metadata": {},
   "source": [
    "### Parte 3: Matem√°tica da Fun√ß√£o de Custo\n",
    "\n",
    "A fun√ß√£o de custo usada para regress√£o log√≠stica √© a m√©dia da perda de log em todos os exemplos de treinamento:\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) $$\n",
    "\n",
    "* $m$ √© o n√∫mero de exemplos de treinamento.\n",
    "* $y^{(i)}$ √© o r√≥tulo real do exemplo de treinamento 'i'.\n",
    "* $h(z^{(i)})$ √© a previs√£o do modelo para o exemplo de treinamento 'i'.\n",
    "\n",
    "A fun√ß√£o de perda para um √∫nico exemplo de treinamento √©\n",
    "\n",
    "$$ Loss = -1 \\times \\left( y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) \\right)$$\n",
    "\n",
    "* Todos os valores de $h$ est√£o entre 0 e 1, ent√£o os logs ser√£o negativos. Essa √© a raz√£o do fator de -1 aplicado √† soma dos dois termos de perda.\n",
    "\n",
    "\n",
    "* Observe que quando o modelo prev√™ 1 ($h(z(\\theta)) = 1$) e o r√≥tulo 'y' tamb√©m √© 1, a perda para esse exemplo de treinamento √© 0.\n",
    "\n",
    "\n",
    "* Da mesma forma, quando o modelo prev√™ 0 ($h(z(\\theta)) = 0$) e o r√≥tulo real tamb√©m √© 0, a perda para esse exemplo de treinamento √© 0.\n",
    "\n",
    "\n",
    "* No entanto, quando a previs√£o do modelo est√° pr√≥xima de 1 ($h(z(\\theta)) = 0,9999$) e o r√≥tulo √© 0, o segundo termo da perda de log torna-se um grande n√∫mero negativo, que √© ent√£o multiplicado pelo total fator de -1 para convert√™-lo em um valor de perda positivo. $-1 \\times (1 - 0) \\times log(1 - 0.9999) \\approx 9.2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab2d68",
   "metadata": {},
   "source": [
    "### Parte 4: Matem√°tica da Atualiza√ß√£o dos Pesos (Descida do Gradiente)\n",
    "\n",
    "Para atualizar o vetor de peso $\\theta$, aplicamos a descida do gradiente para melhorar iterativamente as previs√µes do modelo.\n",
    "\n",
    "O gradiente da fun√ß√£o de custo $J$ em rela√ß√£o a um dos pesos $\\theta_j$ √©:\n",
    "\n",
    "$$\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h^{(i)}-y^{(i)})x^{(i)}_j $$\n",
    "\n",
    "* 'i' √© o √≠ndice em todos os exemplos de treinamento 'm'.\n",
    "* 'j' √© o √≠ndice do peso $\\theta_j$, ent√£o $x^{(i)}_j$ √© o recurso associado ao peso $\\theta_j$\n",
    "\n",
    "* Para atualizar o peso $\\theta_j$, ajustamos subtraindo uma fra√ß√£o do gradiente determinado por $\\alpha$:\n",
    "\n",
    "$$\\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j}J(\\theta) $$\n",
    "\n",
    "* A taxa de aprendizado $\\alpha$ √© um valor que escolhemos para controlar o tamanho de uma √∫nica atualiza√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef67d75",
   "metadata": {},
   "source": [
    "### Parte 5: Combinando Todas as Opera√ß√µes e Criando o Algoritmo\n",
    "\n",
    "* O n√∫mero de itera√ß√µes 'num_iters\" √© o n√∫mero de vezes que voc√™ usar√° todo o conjunto de treinamento (n√∫mero de passadas de treinamento).\n",
    "\n",
    "\n",
    "* Para cada itera√ß√£o, voc√™ calcular√° a fun√ß√£o de custo usando todos os exemplos de treinamento (existem 'm' exemplos de treinamento) e para todos os recursos.\n",
    "\n",
    "\n",
    "* Em vez de atualizar um √∫nico peso $\\theta_i$ de cada vez, podemos atualizar todos os pesos no vetor de coluna:\n",
    "\n",
    "$$\\mathbf{\\theta} = \\begin{pmatrix}\n",
    "\\theta_0\n",
    "\\\\\n",
    "\\theta_1\n",
    "\\\\ \n",
    "\\theta_2 \n",
    "\\\\ \n",
    "\\vdots\n",
    "\\\\ \n",
    "\\theta_n\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "* $\\mathbf{\\theta}$ tem dimens√µes (n+1, 1), onde 'n' √© o n√∫mero de recursos e h√° mais um elemento para o termo de vi√©s $\\theta_0$.\n",
    "\n",
    "\n",
    "* Os 'logits', 'z', s√£o calculados multiplicando a matriz de caracter√≠sticas 'x' pelo vetor de peso 'theta'. $z = \\mathbf{x}\\mathbf{\\theta}$\n",
    "    * $\\mathbf{x}$ tem dimens√µes (m, n+1) \n",
    "    * $\\mathbf{\\theta}$: tem dimens√µes (n+1, 1)\n",
    "    * $\\mathbf{z}$: tem dimens√µes (m, 1)\n",
    "\n",
    "\n",
    "* A predi√ß√£o 'h', √© calculada aplicando o sigm√≥ide a cada elemento em 'z': $h(z) = sigmoid(z)$, e tem dimens√µes (m,1).\n",
    "\n",
    "\n",
    "* A fun√ß√£o de custo $J$ √© calculada atrav√©s do produto escalar dos vetores 'y' e 'log(h)'. Como 'y' e 'h' s√£o vetores coluna (m,1), fazemos a transposta do vetor para a esquerda, de modo que a multiplica√ß√£o da matriz de um vetor linha com o vetor coluna execute o produto escalar.\n",
    "\n",
    "$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n",
    "\n",
    "\n",
    "* A atualiza√ß√£o de $\\theta$ tamb√©m √© vetorizada. Como as dimens√µes de $\\mathbf{x}$ s√£o (m, n+1) e $\\mathbf{h}$ e $\\mathbf{y}$ s√£o (m, 1), precisamos transpor o $ \\mathbf{x}$ √† esquerda para realizar a multiplica√ß√£o de matrizes, o que resulta na resposta (n+1, 1) de que precisamos:\n",
    "\n",
    "$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5323bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para o algoritmo de regress√£o log√≠stica\n",
    "def algo_reg_log(x, y, theta, alpha, num_iters):\n",
    "\n",
    "    # Obter 'm', o n√∫mero de linhas na matriz x\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    for i in range(0, num_iters):\n",
    "        \n",
    "        # Obter z, o produto escalar de x e teta\n",
    "        z = np.dot(x,theta)\n",
    "        \n",
    "        # Obter sigmoid de h\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        # Calcula a fun√ß√£o de custo\n",
    "        # Note que podemos usar tamb√©m np.array.transpose() ao inv√©s de np.array.T\n",
    "        # np.array.T apenas torna o c√≥digo um pouco mais leg√≠vel \n",
    "        J = -1./m * (np.dot(y.T, np.log(h)) + np.dot((1-y).T, np.log(1-h)))                                                    \n",
    "\n",
    "        # Atualiza os pesos theta\n",
    "        theta = theta - (alpha/m) * np.dot(x.T,(h-y))\n",
    "        \n",
    "    J = float(J)\n",
    "    \n",
    "    return J, theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f7fdcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69e4b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A entrada X √© 10 x 3 com 1 para o termo de vi√©s\n",
    "dados_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5eb7c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels Y s√£o 10 x 1\n",
    "dados_Y = (np.random.rand(10, 1) > 0.35).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "364525dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/35/92nflmcn1f17c5zd6dd_gllh0000gn/T/ipykernel_99391/2498321236.py:23: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  J = float(J)\n"
     ]
    }
   ],
   "source": [
    "# Aplica a fun√ß√£o\n",
    "valor_J, valor_theta = algo_reg_log(dados_X, dados_Y, np.zeros((3, 1)), 1e-8, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65d14dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custo (erro) ap√≥s o treinamento √© 0.67094970\n",
      "\n",
      "O vetor de pesos resultante √© [4.1e-07, 0.00035658, 7.309e-05]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nCusto (erro) ap√≥s o treinamento √© {valor_J:.8f}\")\n",
    "print(f\"\\nO vetor de pesos resultante √© {[round(t, 8) for t in np.squeeze(valor_theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e41d043",
   "metadata": {},
   "source": [
    "## Extra√ß√£o de Atributos\n",
    "\n",
    "Com o algoritmo pronto vamos extrair os atributos dos dados e treinar um modelo.\n",
    "\n",
    "* Dada uma lista de tweets, extra√≠mos os recursos e armazenamos em um vetor. Vamos extrair dois recursos:\n",
    "\n",
    "     * A primeira caracter√≠stica √© o n√∫mero de palavras positivas em um tweet.\n",
    "     * A segunda caracter√≠stica √© o n√∫mero de palavras negativas em um tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473310e9",
   "metadata": {},
   "source": [
    "A fun√ß√£o abaixo realiza as seguintes tarefas:\n",
    "\n",
    "* Processa o tweet usando a fun√ß√£o `limpa_processa_tweet` e salvamos a lista de palavras do tweet.\n",
    "\n",
    "\n",
    "* Percorre cada palavra na lista de palavras processadas.\n",
    "\n",
    "\n",
    "* Para cada palavra, verificamos o dicion√°rio de frequ√™ncias 'freqs' para a contagem quando essa palavra tiver um r√≥tulo '1' positivo. Fazemos o mesmo para a contagem quando a palavra estiver associada ao r√≥tulo negativo '0'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6f0e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para extra√ß√£o de atributos\n",
    "def func_extract_features(tweet, freqs):\n",
    "    \n",
    "    # Aplica a fun√ß√£o de limpeza e processamento\n",
    "    word_l = limpa_processa_tweet(tweet)\n",
    "    \n",
    "    # Cria o vetor x de 3 elementos na forma 1 x 3 \n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    # O termo de bias ser√° definido como 1\n",
    "    x[0,0] = 1 \n",
    "        \n",
    "    # Loop pelas palavras\n",
    "    for word in word_l:\n",
    "        \n",
    "        # Palavra de tweet positivo\n",
    "        x[0,1] += freqs.get((word, 1.0),0)\n",
    "        \n",
    "        # Palavra de tweet negativo\n",
    "        x[0,2] += freqs.get((word, 0.0),0)\n",
    "      \n",
    "    # Valida o shape\n",
    "    assert(x.shape == (1, 3))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165bde79",
   "metadata": {},
   "source": [
    "## Treinamento do Modelo\n",
    "\n",
    "Para treinar o modelo:\n",
    "\n",
    "* Empilhamos os recursos de todos os exemplos de treinamento em uma matriz X.\n",
    "\n",
    "* Executamos o algoritmo `algo_reg_log`, implementado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5135a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos a matriz X\n",
    "X = np.zeros((len(dados_treino_x), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c083c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop para preencher a matriz com os dados\n",
    "for i in range(len(dados_treino_x)):\n",
    "    X[i, :]= func_extract_features(dados_treino_x[i], freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "363ed613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vari√°vel de sa√≠da (target)\n",
    "Y = y_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e57e134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperpar√¢metros\n",
    "\n",
    "# Valor inicial da matriz de pesos\n",
    "matriz_pesos = np.zeros((3, 1))\n",
    "\n",
    "# Taxa de aprendizado\n",
    "taxa_aprendizado_alfa = 1e-9\n",
    "\n",
    "# N√∫mero de itera√ß√µes\n",
    "num_iters = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2362867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/35/92nflmcn1f17c5zd6dd_gllh0000gn/T/ipykernel_99391/2498321236.py:23: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  J = float(J)\n"
     ]
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "custo, pesos = algo_reg_log(X, Y, matriz_pesos, taxa_aprendizado_alfa, num_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7505066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Custo (Erro) de Treinamento foi 0.24217172.\n"
     ]
    }
   ],
   "source": [
    "print(f\"O Custo (Erro) de Treinamento foi {custo:.8f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f01e5816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Vetor de Pesos √© [7e-08, 0.00052352, -0.00055579]\n"
     ]
    }
   ],
   "source": [
    "print(f\"O Vetor de Pesos √© {[round(t, 8) for t in np.squeeze(pesos)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a27fd5",
   "metadata": {},
   "source": [
    "S√£o 3 pesos pois temos 2 atributos de entrada e o bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e4b99",
   "metadata": {},
   "source": [
    "## Previs√µes com o Modelo\n",
    "\n",
    "√â hora de fazer previs√µes com o modelo de regress√£o log√≠stica em alguma nova entrada de dados. O objetivo √© prever se um tweet tem sentimento positivo ou negativo.\n",
    "\n",
    "Vamos criar uma fun√ß√£o para isso que executar√° as seguintes tarefas:\n",
    "\n",
    "* Dado um tweet, processamos e extra√≠mos os recursos (o que mesmo que foi feito nso dados de treino).\n",
    "* Aplicamos os pesos aprendidos do modelo para obter os logits.\n",
    "* Aplicamos a fun√ß√£o sigm√≥ide aos logits para obter a previs√£o (um valor entre 0 e 1).\n",
    "\n",
    "Resumindo:\n",
    "\n",
    "$$y_{pred} = sigmoide(\\mathbf{x} \\cdot \\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8989f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para previs√£o\n",
    "def func_previsao(tweet, freqs, theta):\n",
    "\n",
    "    # Extrai os atributos\n",
    "    x = func_extract_features(tweet, freqs)\n",
    "    \n",
    "    # Faz a previsao\n",
    "    y_pred = sigmoid(np.dot(x, theta))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e8a50186",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":) -> 0.815979\n",
      ":( -> 0.115541\n",
      "I am happy -> 0.518562\n",
      "This course is great -> 0.515915\n",
      "I do not expect so much from my soccer team -> 0.494469\n",
      "It was a good book -> 0.513071\n",
      "I am not sure about the text -> 0.500994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/35/92nflmcn1f17c5zd6dd_gllh0000gn/T/ipykernel_99391/641098418.py:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print( '%s -> %f' % (tweet, func_previsao(tweet, freqs, pesos)))\n"
     ]
    }
   ],
   "source": [
    "# Vamos testar a fun√ß√£o\n",
    "for tweet in [':)', \n",
    "              ':(', \n",
    "              'I am happy', \n",
    "              'This course is great', \n",
    "              'I do not expect so much from my soccer team', \n",
    "              'It was a good book', \n",
    "              'I am not sure about the text']:\n",
    "    print( '%s -> %f' % (tweet, func_previsao(tweet, freqs, pesos)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03526ebe",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o do Modelo\n",
    "\n",
    "Vamos agora avaliar a performance do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db1b67d",
   "metadata": {},
   "source": [
    "Vamos criar uma fun√ß√£o para testar o modelo que executar√° as seguintes tarefas:\n",
    "\n",
    "* Recebe os dados de teste e os pesos do modelo treinado e calcula a precis√£o do modelo.\n",
    "* Usa a fun√ß√£o `func_previsao` para fazer previs√µes sobre cada tweet no conjunto de teste.\n",
    "* Se a previs√£o for > 0,5, definimos a classifica√ß√£o do modelo 'y_hat' como 1, caso contr√°rio, definimos a classifica√ß√£o do modelo `y_pred` como 0.\n",
    "* Uma previs√£o √© precisa quando o `y_pred` √© igual ao `y_teste`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d225c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para testar o modelo\n",
    "def func_testa_modelo(test_x, test_y, freqs, theta):\n",
    "\n",
    "    # Lista para s previs√µes\n",
    "    y_hat = []\n",
    "    \n",
    "    # Loop pelos dados\n",
    "    for tweet in test_x:\n",
    "        \n",
    "        # Faz a previs√£o\n",
    "        y_pred = func_previsao(tweet, freqs, theta)\n",
    "        \n",
    "        # Cutoff\n",
    "        if y_pred > 0.5:\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            # append 0 to the list\n",
    "            y_hat.append(0)\n",
    "\n",
    "    # Calcula a acur√°cia\n",
    "    accuracy = (y_hat==np.squeeze(test_y)).sum() / len(test_x)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "951cd5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia = func_testa_modelo(dados_teste_x, y_teste, freqs, pesos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "425f10dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia do Modelo = 0.9965\n"
     ]
    }
   ],
   "source": [
    "print(f\"Acur√°cia do Modelo = {acuracia:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4985bd6b",
   "metadata": {},
   "source": [
    "## Deploy do Modelo Treinado e Uso com Novos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ff7d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um tweet\n",
    "meu_tweet_1 = 'I worked hard today, but I m very happy.!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "70fe8fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['work', 'hard', 'today', 'happi']\n"
     ]
    }
   ],
   "source": [
    "print(limpa_processa_tweet(meu_tweet_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5899cf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51195046]]\n"
     ]
    }
   ],
   "source": [
    "# Previs√£o\n",
    "y_hat = func_previsao(meu_tweet_1, freqs, pesos)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e2f10ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Tweet tem sentimento positivo!\n"
     ]
    }
   ],
   "source": [
    "# Cutoff\n",
    "if y_hat > 0.5:\n",
    "    print('O Tweet tem sentimento positivo!')\n",
    "else: \n",
    "    print('O Tweet tem sentimento negativo!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "578e4451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um tweet\n",
    "meu_tweet_2 = 'My boss is angry today üòí!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ec0dab1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boss', 'angri', 'today', 'üòí']\n"
     ]
    }
   ],
   "source": [
    "print(limpa_processa_tweet(meu_tweet_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "842a7510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49774537]]\n"
     ]
    }
   ],
   "source": [
    "# Previs√£o\n",
    "y_hat = func_previsao(meu_tweet_2, freqs, pesos)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0c475090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Tweet tem sentimento negativo!\n"
     ]
    }
   ],
   "source": [
    "# Cutoff\n",
    "if y_hat > 0.5:\n",
    "    print('O Tweet tem sentimento positivo!')\n",
    "else: \n",
    "    print('O Tweet tem sentimento negativo!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04d1f9",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
